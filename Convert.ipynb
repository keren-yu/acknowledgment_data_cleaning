{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMqHiGUmV76Xw3jBRoZyfga",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/keren-yu/acknowledgment_data_cleaning/blob/main/Convert.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rm8HeIbglOTN",
        "outputId": "e5cdb3c7-9ab4-4abe-b0e5-e42686b03b2f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "save_path = '/content/drive/My Drive/DataCleaning/Convert.ipynb'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Priliminary data tidying\n",
        "Converting json files extracted from Dimention into spreasheet for valid acknowledgement section.\n",
        "\n",
        "The jupyter notebook was originally created and edited with Google colab."
      ],
      "metadata": {
        "id": "-PwRzwUxwfeh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "# Define the path to my working folder\n",
        "data_cleaning_path = \"/content/drive/My Drive/DataCleaning\"\n",
        "\n",
        "# Change the working directory\n",
        "os.chdir(data_cleaning_path)\n",
        "\n",
        "# Verify the current working directory\n",
        "print(\"Current Directory:\", os.getcwd())\n",
        "print(os.listdir())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zdoUpESOnZSi",
        "outputId": "2e5d43cb-95c2-4f12-b59d-f97d6e0cd1cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current Directory: /content/drive/My Drive/DataCleaning\n",
            "['first_batch_publications.json', 'second_batch_publications.json', 'second_batch.xlsx', 'first_batch.xlsx', 'filtered_first_batch.xlsx', 'filtered_second_batch.xlsx', 'Cleaning method.gdoc', 'Convert.ipynb']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "# Load the JSON file\n",
        "file_path = \"second_batch_publications.json\"\n",
        "\n",
        "with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
        "    data = json.load(file)\n",
        "\n",
        "# Extract relevant information\n",
        "entries = []\n",
        "for entry in data:\n",
        "    acknowledgements = entry.get(\"acknowledgements\", \"\").strip()\n",
        "    has_acknowledgement = bool(acknowledgements)  # Check if it is not empty\n",
        "\n",
        "    entries.append({\n",
        "        \"ID\": entry.get(\"id\", \"N/A\"),\n",
        "        \"Year\": entry.get(\"year\", \"N/A\"),\n",
        "        \"Acknowledgement Present\": has_acknowledgement,\n",
        "        \"Acknowledgement Text\": acknowledgements\n",
        "    })\n",
        "\n",
        "# Convert to DataFrame\n",
        "df = pd.DataFrame(entries)\n",
        "\n",
        "# Define the output directory and file path\n",
        "output_dir = \"/content/drive/My Drive/DataCleaning\"  # Change to your desired directory\n",
        "output_file = os.path.join(output_dir, \"second_batch.xlsx\")\n",
        "\n",
        "# Save to an Excel file\n",
        "df.to_excel(output_file, index=False)\n",
        "\n",
        "print(f\"Spreadsheet saved to {output_file}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5SO13fjlousB",
        "outputId": "a029b739-3776-4b7f-ea3a-4f38839a4ebd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spreadsheet saved to /content/drive/My Drive/DataCleaning/second_batch.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "#Load excel file\n",
        "file_path = \"second_batch.xlsx\"\n",
        "df = pd.read_excel(file_path)\n",
        "\n",
        "# Make sure Column D is acknowledgment\n",
        "ack_column = df.columns[3]  # D列 (索引從0開始，所以D列是索引3)\n",
        "\n",
        "# Filter key words\n",
        "keywords = [\"thank\", \"gratitude\", \"acknowledge\", \"appreciate\", \"debt to\", \"grateful\", \"appreciative\" ]\n",
        "df_filtered = df[df[ack_column].str.contains('|'.join(keywords), case=False, na=False)]\n",
        "\n",
        "# 儲存篩選結果\n",
        "output_file = \"filtered_second_batch_new_key.xlsx\"\n",
        "df_filtered.to_excel(output_file, index=False)\n",
        "\n",
        "print(f\"篩選完成，結果已保存至 {output_file}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9LlI7_qD6iZF",
        "outputId": "5d03510f-b234-467a-c8e5-72f4bf0139f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "篩選完成，結果已保存至 filtered_second_batch_new_key.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "# Load the JSON file\n",
        "file_path = \"first_batch_publications.json\"\n",
        "\n",
        "with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
        "    data = json.load(file)\n",
        "\n",
        "# Extract relevant information\n",
        "entries = []\n",
        "for entry in data:\n",
        "    acknowledgements = entry.get(\"acknowledgements\", \"\").strip()\n",
        "    has_acknowledgement = bool(acknowledgements)  # Check if it is not empty\n",
        "\n",
        "    entries.append({\n",
        "        \"ID\": entry.get(\"id\", \"N/A\"),\n",
        "        \"Year\": entry.get(\"year\", \"N/A\"),\n",
        "        \"Acknowledgement Present\": has_acknowledgement,\n",
        "        \"Acknowledgement Text\": acknowledgements\n",
        "    })\n",
        "\n",
        "# Convert to DataFrame\n",
        "df = pd.DataFrame(entries)\n",
        "\n",
        "# Define the output directory and file path\n",
        "output_dir = \"/content/drive/My Drive/DataCleaning\"  # Change to your desired directory\n",
        "output_file = os.path.join(output_dir, \"first_batch.xlsx\")\n",
        "\n",
        "# Save to an Excel file\n",
        "df.to_excel(output_file, index=False)\n",
        "\n",
        "print(f\"Spreadsheet saved to {output_file}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zDsc01rK-zSX",
        "outputId": "47088815-9982-4906-9e3c-985368d69a1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spreadsheet saved to /content/drive/My Drive/DataCleaning/first_batch.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# 讀取 Excel 文件\n",
        "file_path = \"first_batch.xlsx\"  # 你的 Excel 文件\n",
        "df = pd.read_excel(file_path)\n",
        "\n",
        "# 確保 D 列是 acknowledgment 欄位\n",
        "ack_column = df.columns[3]  # D列 (索引從0開始，所以D列是索引3)\n",
        "\n",
        "# 關鍵詞篩選\n",
        "keywords = [\"thank\", \"gratitude\", \"appreciate\"]\n",
        "df_filtered = df[df[ack_column].str.contains('|'.join(keywords), case=False, na=False)]\n",
        "\n",
        "# 儲存篩選結果\n",
        "output_file = \"filtered_first_batch.xlsx\"\n",
        "df_filtered.to_excel(output_file, index=False)\n",
        "\n",
        "print(f\"篩選完成，結果已保存至 {output_file}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fSfJJQK6_stR",
        "outputId": "d3c6c258-7461-4213-94c9-ec554fbba757"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "篩選完成，結果已保存至 filtered_first_batch.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "print(sys.version)\n"
      ],
      "metadata": {
        "id": "dG4DI3ApUdan",
        "outputId": "ce76e0cc-dcb7-4bd4-a7db-e43c4f09721a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.11.11 (main, Dec  4 2024, 08:55:07) [GCC 11.4.0]\n"
          ]
        }
      ]
    }
  ]
}